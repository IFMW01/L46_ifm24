{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5UR0O-BbO19",
        "outputId": "51dc7954-9b5c-4afe-a016-3547c3ef92f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.10/dist-packages (0.7.5)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.23.5)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.16.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "!pip install tensorflow-model-optimization\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "from tensorflow.keras.models import load_model\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import gc\n",
        "from keras.datasets import cifar100\n",
        "from tensorflow.keras import layers\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgdWDGbE0e-h",
        "outputId": "81e6531c-bef4-4486-b938-3d2ba896a092"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "def build_model(input_shape, num_classes):\n",
        "    model= tf.keras.applications.MobileNet(\n",
        "    input_shape=input_shape,\n",
        "    include_top=None,\n",
        "    weights=None,\n",
        "    pooling='avg',\n",
        "    classes=num_classes,\n",
        "    )\n",
        "    for layer in model.layers:\n",
        "      layer.trainable=True\n",
        "    dnn_model = keras.Sequential()\n",
        "    dnn_model.add(model)\n",
        "    dnn_model.add(keras.layers.Flatten())\n",
        "    dnn_model.add(keras.layers.Dense(512, activation='relu'))\n",
        "    dnn_model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
        "    dnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return dnn_model\n",
        "\n",
        "num_classes = 100\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISdhEM6VaVA4"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_data, train_labels, test_data, test_labels):\n",
        "    model.save_weights(init_weights)\n",
        "    model.save(init_model)\n",
        "    initailsoftmax = model.predict(test_data)\n",
        "    initaildf = pd.DataFrame(initailsoftmax)\n",
        "    filename = filepath + '0_softmax.csv'\n",
        "    initaildf.to_csv(filename,index=False)\n",
        "    epoch = 1\n",
        "    while epoch < 26:\n",
        "        print(f\"Epoch {epoch}:\")\n",
        "\n",
        "        # Training on one epoch\n",
        "        model.fit(train_data, train_labels, epochs=1, batch_size=64, verbose=1)\n",
        "\n",
        "        # Evaluate on the test dataset\n",
        "        loss, accuracy = model.evaluate(test_data, test_labels, verbose=0)\n",
        "        results = model.predict(test_data)\n",
        "        softmax_df = pd.DataFrame(results)\n",
        "        filename = filepath+str(epoch)+'_softmax.csv'\n",
        "        softmax_df.to_csv(filename,index=False)\n",
        "\n",
        "        print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
        "        if epoch ==25:\n",
        "          model.save_weights(final_weights)\n",
        "          model.save(final_model)\n",
        "        epoch += 1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZW6sVYElRjz-"
      },
      "outputs": [],
      "source": [
        "model_name = 'mobilenet'\n",
        "dataset = 'CIFAR100'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EJSiXMAb4UR"
      },
      "source": [
        "# Creating Base Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WZTNNxJciha"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/base/'\n",
        "init_weights = filepath + model_name + dataset + '_init_weights.tf'\n",
        "init_model = filepath + model_name + dataset +'_init.tf'\n",
        "final_weights = filepath + model_name + dataset +'_final_weights.tf'\n",
        "final_model= filepath + model_name + dataset +'_final.tf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slUSKBbwgTV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56946cfe-c781-429f-a977-f6684a384feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/base/’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir '/content/base/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws_M91l3fZ24"
      },
      "outputs": [],
      "source": [
        "base = build_model(input_shape, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEAxJbswxiTX",
        "outputId": "df280788-c1b0-40cc-c90e-a3bc6806e170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`mobilenet_1.00_32_input` is not a valid tf.function parameter name. Sanitizing to `mobilenet_1_00_32_input`.\n",
            "WARNING:absl:`mobilenet_1.00_32_input` is not a valid tf.function parameter name. Sanitizing to `mobilenet_1_00_32_input`.\n",
            "WARNING:absl:`mobilenet_1.00_32_input` is not a valid tf.function parameter name. Sanitizing to `mobilenet_1_00_32_input`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 6s 5ms/step\n",
            "Epoch 1:\n",
            "782/782 [==============================] - 35s 24ms/step - loss: 4.2640 - accuracy: 0.0456\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 4.032528877258301, Test Accuracy: 0.07109999656677246\n",
            "Epoch 2:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 3.8156 - accuracy: 0.0992\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 4.094801425933838, Test Accuracy: 0.08969999849796295\n",
            "Epoch 3:\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 3.5704 - accuracy: 0.1362\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 3.9689788818359375, Test Accuracy: 0.1062999963760376\n",
            "Epoch 4:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 3.3883 - accuracy: 0.1702\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.9131293296813965, Test Accuracy: 0.14069999754428864\n",
            "Epoch 5:\n",
            "782/782 [==============================] - 18s 24ms/step - loss: 3.2314 - accuracy: 0.1982\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.464887857437134, Test Accuracy: 0.1817999929189682\n",
            "Epoch 6:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 3.0820 - accuracy: 0.2254\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.9440624713897705, Test Accuracy: 0.15680000185966492\n",
            "Epoch 7:\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 2.9398 - accuracy: 0.2537\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.8659987449645996, Test Accuracy: 0.1712999939918518\n",
            "Epoch 8:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.8072 - accuracy: 0.2783\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.529686689376831, Test Accuracy: 0.19509999454021454\n",
            "Epoch 9:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.6732 - accuracy: 0.3054\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 3.293795347213745, Test Accuracy: 0.23929999768733978\n",
            "Epoch 10:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.5360 - accuracy: 0.3329\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.3046629428863525, Test Accuracy: 0.24639999866485596\n",
            "Epoch 11:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.4139 - accuracy: 0.3572\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.251858711242676, Test Accuracy: 0.25679999589920044\n",
            "Epoch 12:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.2838 - accuracy: 0.3858\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "Test Loss: 3.1905996799468994, Test Accuracy: 0.27480000257492065\n",
            "Epoch 13:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.1581 - accuracy: 0.4140\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.369042158126831, Test Accuracy: 0.2678000032901764\n",
            "Epoch 14:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.0481 - accuracy: 0.4375\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.372553586959839, Test Accuracy: 0.2689000070095062\n",
            "Epoch 15:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.9432 - accuracy: 0.4619\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.229700803756714, Test Accuracy: 0.2849999964237213\n",
            "Epoch 16:\n",
            "782/782 [==============================] - 20s 26ms/step - loss: 1.8252 - accuracy: 0.4871\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.3918700218200684, Test Accuracy: 0.27709999680519104\n",
            "Epoch 17:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.7350 - accuracy: 0.5076\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.6090481281280518, Test Accuracy: 0.25780001282691956\n",
            "Epoch 18:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.6360 - accuracy: 0.5333\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 3.5051422119140625, Test Accuracy: 0.28940001130104065\n",
            "Epoch 19:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.5470 - accuracy: 0.5522\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.568403959274292, Test Accuracy: 0.28600001335144043\n",
            "Epoch 20:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.4669 - accuracy: 0.5735\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.782848834991455, Test Accuracy: 0.27630001306533813\n",
            "Epoch 21:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.3826 - accuracy: 0.5947\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 3.7163026332855225, Test Accuracy: 0.287200003862381\n",
            "Epoch 22:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.3126 - accuracy: 0.6125\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.8656909465789795, Test Accuracy: 0.28209999203681946\n",
            "Epoch 23:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.2357 - accuracy: 0.6314\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 4.167272090911865, Test Accuracy: 0.2718999981880188\n",
            "Epoch 24:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.1663 - accuracy: 0.6488\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.9559969902038574, Test Accuracy: 0.2849999964237213\n",
            "Epoch 25:\n",
            "782/782 [==============================] - 19s 25ms/step - loss: 1.1058 - accuracy: 0.6660\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 4.008255481719971, Test Accuracy: 0.29120001196861267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`mobilenet_1.00_32_input` is not a valid tf.function parameter name. Sanitizing to `mobilenet_1_00_32_input`.\n",
            "WARNING:absl:`mobilenet_1.00_32_input` is not a valid tf.function parameter name. Sanitizing to `mobilenet_1_00_32_input`.\n"
          ]
        }
      ],
      "source": [
        "train_model(base,x_train,y_train,x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJTpZuPCRNuO"
      },
      "outputs": [],
      "source": [
        "del (base)\n",
        "gc.collect()\n",
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive(\"base\", 'zip', \"base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ur_5EgKU2dIb",
        "outputId": "9004f5e6-1fe8-4b4d-f0a3-1a445b8a89ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/base.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colab_link = \"/content/base.zip\"\n",
        "gdrive_link = \"/content/drive/MyDrive/MobileNet_CIFAR100\"\n",
        "shutil.copy(colab_link, gdrive_link)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3HHnx5Ee2cJN",
        "outputId": "f30640c9-fa99-42db-cd0c-7e77273f01bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/MobileNet_CIFAR100/base.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug9epnRWclXx"
      },
      "source": [
        "# Independant model one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgYyTzPGckv5"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/independant_1/'\n",
        "init_weights = filepath + model_name + dataset + '_init_weights.tf'\n",
        "init_model = filepath + model_name + dataset + '_init.tf'\n",
        "final_weights = filepath + model_name + dataset + '_final_weights.tf'\n",
        "final_model= filepath + model_name + dataset + '_final.tf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a27D5LR5gpFp"
      },
      "outputs": [],
      "source": [
        "!mkdir  '/content/independant_1/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZmvRweSc6P8"
      },
      "outputs": [],
      "source": [
        "model_independant_1 = build_model(input_shape, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbSGMFzRdA5Z",
        "outputId": "22805582-54c9-43ca-dea2-02ac80834d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 4ms/step\n",
            "Epoch 1:\n",
            "782/782 [==============================] - 30s 23ms/step - loss: 4.1942 - accuracy: 0.0572\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 4.0796356201171875, Test Accuracy: 0.0754999965429306\n",
            "Epoch 2:\n",
            "782/782 [==============================] - 19s 25ms/step - loss: 3.7422 - accuracy: 0.1137\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 4.045466899871826, Test Accuracy: 0.1080000028014183\n",
            "Epoch 3:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 3.5055 - accuracy: 0.1516\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.8095145225524902, Test Accuracy: 0.13580000400543213\n",
            "Epoch 4:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 3.3246 - accuracy: 0.1860\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.744938373565674, Test Accuracy: 0.1535000056028366\n",
            "Epoch 5:\n",
            "782/782 [==============================] - 20s 26ms/step - loss: 3.1743 - accuracy: 0.2115\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.6420843601226807, Test Accuracy: 0.17810000479221344\n",
            "Epoch 6:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 3.0357 - accuracy: 0.2341\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.5965542793273926, Test Accuracy: 0.19449999928474426\n",
            "Epoch 7:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.8943 - accuracy: 0.2609\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.4585020542144775, Test Accuracy: 0.21490000188350677\n",
            "Epoch 8:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.7545 - accuracy: 0.2885\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.320676565170288, Test Accuracy: 0.227400004863739\n",
            "Epoch 9:\n",
            "782/782 [==============================] - 18s 24ms/step - loss: 2.6238 - accuracy: 0.3165\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.480116367340088, Test Accuracy: 0.22210000455379486\n",
            "Epoch 10:\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 2.4949 - accuracy: 0.3454\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 3.268339157104492, Test Accuracy: 0.2484000027179718\n",
            "Epoch 11:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.3654 - accuracy: 0.3712\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.3306026458740234, Test Accuracy: 0.251800000667572\n",
            "Epoch 12:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.2447 - accuracy: 0.3965\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.1539783477783203, Test Accuracy: 0.27000001072883606\n",
            "Epoch 13:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.1276 - accuracy: 0.4234\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.3164761066436768, Test Accuracy: 0.26109999418258667\n",
            "Epoch 14:\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 2.0179 - accuracy: 0.4464\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.3361055850982666, Test Accuracy: 0.25360000133514404\n",
            "Epoch 15:\n",
            "782/782 [==============================] - 18s 24ms/step - loss: 1.9127 - accuracy: 0.4672\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.5040972232818604, Test Accuracy: 0.24560000002384186\n",
            "Epoch 16:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.8110 - accuracy: 0.4937\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.5914957523345947, Test Accuracy: 0.24860000610351562\n",
            "Epoch 17:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.7218 - accuracy: 0.5153\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "Test Loss: 3.5662102699279785, Test Accuracy: 0.2644999921321869\n",
            "Epoch 18:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.6291 - accuracy: 0.5353\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 3.5270960330963135, Test Accuracy: 0.2676999866962433\n",
            "Epoch 19:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.5524 - accuracy: 0.5527\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 3.5367047786712646, Test Accuracy: 0.27889999747276306\n",
            "Epoch 20:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.4571 - accuracy: 0.5794\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.619863748550415, Test Accuracy: 0.28299999237060547\n",
            "Epoch 21:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.4039 - accuracy: 0.5908\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.7327487468719482, Test Accuracy: 0.2700999975204468\n",
            "Epoch 22:\n",
            "782/782 [==============================] - 19s 25ms/step - loss: 1.3306 - accuracy: 0.6090\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.7978453636169434, Test Accuracy: 0.27390000224113464\n",
            "Epoch 23:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.2531 - accuracy: 0.6273\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.923618793487549, Test Accuracy: 0.2842999994754791\n",
            "Epoch 24:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.1857 - accuracy: 0.6455\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "Test Loss: 3.892216444015503, Test Accuracy: 0.29409998655319214\n",
            "Epoch 25:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.1323 - accuracy: 0.6618\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.95353364944458, Test Accuracy: 0.28450000286102295\n"
          ]
        }
      ],
      "source": [
        "train_model(model_independant_1,x_train,y_train,x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW6INm6kSxFS"
      },
      "outputs": [],
      "source": [
        "del (model_independant_1)\n",
        "gc.collect()\n",
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2OTEYTFdUAE"
      },
      "source": [
        "# Independant 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_6iAeLLdWyf"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/independant_2/'\n",
        "init_weights = filepath + model_name + dataset + '_init_weights.tf'\n",
        "init_model = filepath + model_name + dataset + '_init.tf'\n",
        "final_weights =filepath + model_name + dataset + '_final_weights.tf'\n",
        "final_model= filepath + model_name + dataset + '_final.tf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qq4QQMaTgwcV"
      },
      "outputs": [],
      "source": [
        "!mkdir '/content/independant_2/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB-QyYy1df0r"
      },
      "outputs": [],
      "source": [
        "model_independant_2 = build_model(input_shape, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axvsh5YIdjHr",
        "outputId": "8d830d4c-5157-4f91-ecd4-bc5c44be3a65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 4ms/step\n",
            "Epoch 1:\n",
            "782/782 [==============================] - 30s 23ms/step - loss: 4.1967 - accuracy: 0.0549\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.946924924850464, Test Accuracy: 0.08190000057220459\n",
            "Epoch 2:\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 3.7806 - accuracy: 0.1060\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.8954429626464844, Test Accuracy: 0.11289999634027481\n",
            "Epoch 3:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 3.5603 - accuracy: 0.1439\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.94465970993042, Test Accuracy: 0.12319999933242798\n",
            "Epoch 4:\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 3.3908 - accuracy: 0.1709\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "Test Loss: 3.7272868156433105, Test Accuracy: 0.15850000083446503\n",
            "Epoch 5:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 3.2285 - accuracy: 0.2053\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 3.5708909034729004, Test Accuracy: 0.17000000178813934\n",
            "Epoch 6:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 3.0724 - accuracy: 0.2316\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 3.7198500633239746, Test Accuracy: 0.1664000004529953\n",
            "Epoch 7:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.9255 - accuracy: 0.2616\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "Test Loss: 3.6094062328338623, Test Accuracy: 0.18809999525547028\n",
            "Epoch 8:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.7844 - accuracy: 0.2873\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 3.44670033454895, Test Accuracy: 0.2102999985218048\n",
            "Epoch 9:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.6486 - accuracy: 0.3144\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.237591505050659, Test Accuracy: 0.23929999768733978\n",
            "Epoch 10:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.5180 - accuracy: 0.3387\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 3.2057299613952637, Test Accuracy: 0.25040000677108765\n",
            "Epoch 11:\n",
            "782/782 [==============================] - 18s 24ms/step - loss: 2.3998 - accuracy: 0.3632\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.26499342918396, Test Accuracy: 0.24570000171661377\n",
            "Epoch 12:\n",
            "782/782 [==============================] - 19s 25ms/step - loss: 2.2775 - accuracy: 0.3878\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.3506782054901123, Test Accuracy: 0.2460000067949295\n",
            "Epoch 13:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.1580 - accuracy: 0.4169\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.357109785079956, Test Accuracy: 0.25110000371932983\n",
            "Epoch 14:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.0437 - accuracy: 0.4390\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.2545740604400635, Test Accuracy: 0.2734000086784363\n",
            "Epoch 15:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.9374 - accuracy: 0.4633\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 3.3338980674743652, Test Accuracy: 0.262800008058548\n",
            "Epoch 16:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.8352 - accuracy: 0.4882\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 3.490525484085083, Test Accuracy: 0.25540000200271606\n",
            "Epoch 17:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.7420 - accuracy: 0.5100\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.339884042739868, Test Accuracy: 0.2809999883174896\n",
            "Epoch 18:\n",
            "782/782 [==============================] - 18s 24ms/step - loss: 1.6415 - accuracy: 0.5343\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.587595224380493, Test Accuracy: 0.2639000117778778\n",
            "Epoch 19:\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.5537 - accuracy: 0.5543\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.471369981765747, Test Accuracy: 0.2766000032424927\n",
            "Epoch 20:\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.4562 - accuracy: 0.5768\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Test Loss: 3.5656914710998535, Test Accuracy: 0.2865999937057495\n",
            "Epoch 21:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.3880 - accuracy: 0.5971\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 3.661189556121826, Test Accuracy: 0.2797999978065491\n",
            "Epoch 22:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.3085 - accuracy: 0.6153\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "Test Loss: 3.7612390518188477, Test Accuracy: 0.2750999927520752\n",
            "Epoch 23:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.2359 - accuracy: 0.6334\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "Test Loss: 3.7956831455230713, Test Accuracy: 0.28119999170303345\n",
            "Epoch 24:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.1774 - accuracy: 0.6496\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "Test Loss: 3.9140448570251465, Test Accuracy: 0.2791000008583069\n",
            "Epoch 25:\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.0970 - accuracy: 0.6740\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "Test Loss: 3.911813735961914, Test Accuracy: 0.28600001335144043\n"
          ]
        }
      ],
      "source": [
        "train_model(model_independant_2,x_train,y_train,x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-t_bBGPKS9oi"
      },
      "outputs": [],
      "source": [
        "del (model_independant_2)\n",
        "gc.collect()\n",
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxQrGkUBYePo"
      },
      "source": [
        "#Download Independant Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive(\"independant_1\", 'zip', \"independant_1\")"
      ],
      "metadata": {
        "id": "RcKQFmnYy7Rn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9a0b41fd-8d27-4087-cf5b-98539fa61fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/independant_1.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "colab_link = \"/content/independant_1.zip\"\n",
        "gdrive_link = \"/content/drive/MyDrive/MobileNet_CIFAR100\"\n",
        "shutil.copy(colab_link, gdrive_link)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Lo0HHNIBuvmS",
        "outputId": "cc969a3f-0010-40c7-9111-444817b32b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/MobileNet_CIFAR100/independant_1.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive(\"independant_2\", 'zip', \"independant_2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cZgOWD-TxT7E",
        "outputId": "34c92ab5-239e-483e-9a4d-6a5add458a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/independant_2.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import drive\n",
        "colab_link = \"/content/independant_2.zip\"\n",
        "gdrive_link = \"/content/drive/MyDrive/MobileNet_CIFAR100\"\n",
        "shutil.copy(colab_link, gdrive_link)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EnX3-k2yyNGC",
        "outputId": "a6570450-0d32-4c7c-8aba-c3190d179810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/MobileNet_CIFAR100/independant_2.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M1eiG9hE3Up"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXdp-pUi2U5_"
      },
      "source": [
        "# Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1gaVGRegqu_"
      },
      "outputs": [],
      "source": [
        "def train_custom(model, train_data, train_labels, test_data, test_labels):\n",
        "    initailsoftmax = model.student.predict(test_data)\n",
        "    model.student.save_weights(init_weights)\n",
        "    model.student.save(init_model)\n",
        "    initaildf = pd.DataFrame(initailsoftmax)\n",
        "    filename = filepath + '0_softmax.csv'\n",
        "    initaildf.to_csv(filename,index=False)\n",
        "    epoch = 1\n",
        "    while epoch < 26:\n",
        "        print(f\"Epoch {epoch}:\")\n",
        "\n",
        "        # Training on one epoch\n",
        "        model.fit(train_data, train_labels, epochs=1, batch_size=64, verbose=1)\n",
        "\n",
        "        # Evaluate on the test dataset\n",
        "        results = model.student.predict(test_data)\n",
        "        softmax_df = pd.DataFrame(results)\n",
        "        filename = filepath+str(epoch)+'_softmax.csv'\n",
        "        softmax_df.to_csv(filename,index=False)\n",
        "        loss,accuracy = model.student.evaluate(test_data,test_labels)\n",
        "        print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
        "\n",
        "        if epoch ==25:\n",
        "          model.student.save_weights(final_weights)\n",
        "          model.student.save(final_model)\n",
        "        epoch += 1\n",
        "\n",
        "# TO DO EVALUATE FUNCTION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfM5ezDj2mCH"
      },
      "outputs": [],
      "source": [
        "class Distiller(tf.keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super().__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha,\n",
        "        temperature,\n",
        "    ):\n",
        "        super().compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of teacher\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of student\n",
        "            student_predictions = self.student(x, training=True)\n",
        "\n",
        "            # Compute losses\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "\n",
        "            distillation_loss = (\n",
        "                self.distillation_loss_fn(\n",
        "                    tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                    tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
        "                )\n",
        "                * self.temperature**2\n",
        "            )\n",
        "\n",
        "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_prediction = self.student(x, training=False)\n",
        "        print(y_prediction)\n",
        "        # Calculate the loss\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": student_loss})\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgQPe37aj3Ek"
      },
      "source": [
        "# Student 0.1 Alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGgaXEX8j7IG"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/base/mobilenetCIFAR100_init.tf'\n",
        "student = load_model(model_path)\n",
        "student_scratch = tf.keras.models.clone_model(student)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab_sFwqB-Tsh"
      },
      "outputs": [],
      "source": [
        "teacher_model_path = '/content/base/mobilenetCIFAR100_final.tf'\n",
        "techer_model = load_model(teacher_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KL5sBYc19ITH"
      },
      "outputs": [],
      "source": [
        "distiller = Distiller(student=student, teacher=techer_model)\n",
        "distiller.compile(\n",
        "    optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001),\n",
        "    metrics=[tf.keras.metrics.CategoricalCrossentropy()],\n",
        "    student_loss_fn=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=tf.keras.losses.KLDivergence(),\n",
        "    alpha=0.1,\n",
        "    temperature=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvIefPKXnZ17"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/student_same/'\n",
        "init_weights = filepath + model_name + dataset + '_init_weights.tf'\n",
        "init_model = filepath + model_name + dataset + '_init.tf'\n",
        "final_weights = filepath + model_name + dataset + '_final_weights.tf'\n",
        "final_model= filepath + model_name + dataset + 'final.tf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqIWgvFfnUH2"
      },
      "outputs": [],
      "source": [
        "!mkdir '/content/student_same/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9Or3ngvlCSk",
        "outputId": "4cd9483b-1fa9-4cc7-b83f-5e36cee69ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 4ms/step\n",
            "Epoch 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5575: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 37s 26ms/step - categorical_crossentropy: 4.3933 - student_loss: 4.3933 - distillation_loss: 0.0030\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 3s 6ms/step - loss: 4.3746 - accuracy: 0.0374\n",
            "Test Loss: 4.374606132507324, Test Accuracy: 0.03739999979734421\n",
            "Epoch 2:\n",
            "782/782 [==============================] - 20s 26ms/step - categorical_crossentropy: 3.9815 - student_loss: 3.9810 - distillation_loss: 0.0029\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 3.9818 - accuracy: 0.0974\n",
            "Test Loss: 3.981781244277954, Test Accuracy: 0.09740000218153\n",
            "Epoch 3:\n",
            "782/782 [==============================] - 20s 26ms/step - categorical_crossentropy: 3.6776 - student_loss: 3.6764 - distillation_loss: 0.0028\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 3.6982 - accuracy: 0.1395\n",
            "Test Loss: 3.6981608867645264, Test Accuracy: 0.13950000703334808\n",
            "Epoch 4:\n",
            "782/782 [==============================] - 20s 26ms/step - categorical_crossentropy: 3.4387 - student_loss: 3.4376 - distillation_loss: 0.0026\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 3.4966 - accuracy: 0.1701\n",
            "Test Loss: 3.4966230392456055, Test Accuracy: 0.17010000348091125\n",
            "Epoch 5:\n",
            "782/782 [==============================] - 20s 26ms/step - categorical_crossentropy: 3.2197 - student_loss: 3.2182 - distillation_loss: 0.0025\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 3.5668 - accuracy: 0.1701\n",
            "Test Loss: 3.566803216934204, Test Accuracy: 0.17010000348091125\n",
            "Epoch 6:\n",
            "782/782 [==============================] - 21s 26ms/step - categorical_crossentropy: 3.0178 - student_loss: 3.0160 - distillation_loss: 0.0024\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 3.4050 - accuracy: 0.2015\n",
            "Test Loss: 3.4050092697143555, Test Accuracy: 0.20149999856948853\n",
            "Epoch 7:\n",
            "782/782 [==============================] - 21s 27ms/step - categorical_crossentropy: 2.8121 - student_loss: 2.8099 - distillation_loss: 0.0023\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 3.4992 - accuracy: 0.1927\n",
            "Test Loss: 3.499225378036499, Test Accuracy: 0.19269999861717224\n",
            "Epoch 8:\n",
            "782/782 [==============================] - 21s 27ms/step - categorical_crossentropy: 2.6164 - student_loss: 2.6144 - distillation_loss: 0.0023\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 3.5628 - accuracy: 0.2001\n",
            "Test Loss: 3.5627949237823486, Test Accuracy: 0.20010000467300415\n",
            "Epoch 9:\n",
            "782/782 [==============================] - 21s 27ms/step - categorical_crossentropy: 2.4368 - student_loss: 2.4341 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 3.7554 - accuracy: 0.1906\n",
            "Test Loss: 3.755392551422119, Test Accuracy: 0.19059999287128448\n",
            "Epoch 10:\n",
            "782/782 [==============================] - 21s 26ms/step - categorical_crossentropy: 2.2670 - student_loss: 2.2646 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 3.7862 - accuracy: 0.2020\n",
            "Test Loss: 3.7861809730529785, Test Accuracy: 0.20200000703334808\n",
            "Epoch 11:\n",
            "782/782 [==============================] - 21s 27ms/step - categorical_crossentropy: 2.1029 - student_loss: 2.1005 - distillation_loss: 0.0021\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 3.7288 - accuracy: 0.2087\n",
            "Test Loss: 3.728837490081787, Test Accuracy: 0.2087000012397766\n",
            "Epoch 12:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.9646 - student_loss: 1.9622 - distillation_loss: 0.0021\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 3.8227 - accuracy: 0.2054\n",
            "Test Loss: 3.8227100372314453, Test Accuracy: 0.2054000049829483\n",
            "Epoch 13:\n",
            "782/782 [==============================] - 21s 27ms/step - categorical_crossentropy: 1.8247 - student_loss: 1.8222 - distillation_loss: 0.0021\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 4.0240 - accuracy: 0.1985\n",
            "Test Loss: 4.0240325927734375, Test Accuracy: 0.19850000739097595\n",
            "Epoch 14:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.7019 - student_loss: 1.6993 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 4.0477 - accuracy: 0.2126\n",
            "Test Loss: 4.0476975440979, Test Accuracy: 0.2125999927520752\n",
            "Epoch 15:\n",
            "782/782 [==============================] - 23s 29ms/step - categorical_crossentropy: 1.5898 - student_loss: 1.5872 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 4.0940 - accuracy: 0.2113\n",
            "Test Loss: 4.093973636627197, Test Accuracy: 0.21130000054836273\n",
            "Epoch 16:\n",
            "782/782 [==============================] - 22s 29ms/step - categorical_crossentropy: 1.4903 - student_loss: 1.4878 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 4.4531 - accuracy: 0.2127\n",
            "Test Loss: 4.453081130981445, Test Accuracy: 0.2126999944448471\n",
            "Epoch 17:\n",
            "782/782 [==============================] - 21s 27ms/step - categorical_crossentropy: 1.3838 - student_loss: 1.3816 - distillation_loss: 0.0023\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 4.4775 - accuracy: 0.2145\n",
            "Test Loss: 4.47747278213501, Test Accuracy: 0.21449999511241913\n",
            "Epoch 18:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.2937 - student_loss: 1.2918 - distillation_loss: 0.0023\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 4.4799 - accuracy: 0.2047\n",
            "Test Loss: 4.479928970336914, Test Accuracy: 0.20469999313354492\n",
            "Epoch 19:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.2003 - student_loss: 1.1982 - distillation_loss: 0.0023\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 4.7512 - accuracy: 0.2091\n",
            "Test Loss: 4.751220703125, Test Accuracy: 0.20909999310970306\n",
            "Epoch 20:\n",
            "782/782 [==============================] - 23s 29ms/step - categorical_crossentropy: 1.1286 - student_loss: 1.1265 - distillation_loss: 0.0024\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 4.8622 - accuracy: 0.2046\n",
            "Test Loss: 4.862183570861816, Test Accuracy: 0.2046000063419342\n",
            "Epoch 21:\n",
            "782/782 [==============================] - 24s 30ms/step - categorical_crossentropy: 1.0530 - student_loss: 1.0509 - distillation_loss: 0.0024\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 4.9277 - accuracy: 0.2054\n",
            "Test Loss: 4.927703857421875, Test Accuracy: 0.2054000049829483\n",
            "Epoch 22:\n",
            "782/782 [==============================] - 23s 29ms/step - categorical_crossentropy: 0.9832 - student_loss: 0.9813 - distillation_loss: 0.0025\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 5.0483 - accuracy: 0.2081\n",
            "Test Loss: 5.048325061798096, Test Accuracy: 0.20810000598430634\n",
            "Epoch 23:\n",
            "782/782 [==============================] - 23s 29ms/step - categorical_crossentropy: 0.9148 - student_loss: 0.9130 - distillation_loss: 0.0025\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 5.0234 - accuracy: 0.2124\n",
            "Test Loss: 5.023366451263428, Test Accuracy: 0.21240000426769257\n",
            "Epoch 24:\n",
            "782/782 [==============================] - 23s 29ms/step - categorical_crossentropy: 0.8481 - student_loss: 0.8465 - distillation_loss: 0.0026\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 5.4180 - accuracy: 0.1989\n",
            "Test Loss: 5.41804313659668, Test Accuracy: 0.1988999992609024\n",
            "Epoch 25:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 0.7959 - student_loss: 0.7944 - distillation_loss: 0.0026\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 5.3246 - accuracy: 0.2090\n",
            "Test Loss: 5.3245649337768555, Test Accuracy: 0.20900000631809235\n"
          ]
        }
      ],
      "source": [
        "train_custom(distiller, x_train,y_train,x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTMYO7__Uzxz"
      },
      "outputs": [],
      "source": [
        "del (student)\n",
        "gc.collect()\n",
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive(\"student_same\", 'zip', \"student_same\")\n",
        "colab_link = \"/content/student_same.zip\"\n",
        "gdrive_link = \"/content/drive/MyDrive/MobileNet_CIFAR100\"\n",
        "shutil.copy(colab_link, gdrive_link)"
      ],
      "metadata": {
        "id": "r3Js-JdJyPm4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d4ef08d8-42f7-41fc-9595-465d3ff1bc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/MobileNet_CIFAR100/student_same.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaN0-7_6U9e6"
      },
      "source": [
        "# Student same Alpha 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLTcfc2UVIfO"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/base/mobilenetCIFAR100_init.tf'\n",
        "student = load_model(model_path)\n",
        "student_scratch = tf.keras.models.clone_model(student)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0xmOf5IVI-G"
      },
      "outputs": [],
      "source": [
        "distiller = Distiller(student=student, teacher=techer_model)\n",
        "distiller.compile(\n",
        "    optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001),\n",
        "    metrics=[tf.keras.metrics.CategoricalCrossentropy()],\n",
        "    student_loss_fn=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=tf.keras.losses.KLDivergence(),\n",
        "    alpha=0.5,\n",
        "    temperature=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4fyr8rwVPsI"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/student_same_50/'\n",
        "init_weights = filepath + model_name + dataset + '_init_weights.tf'\n",
        "init_model = filepath + model_name + dataset + '_init.tf'\n",
        "final_weights = filepath + model_name + dataset + '_final_weights.tf'\n",
        "final_model= filepath + model_name + dataset + 'final.tf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzbhPktzVokH"
      },
      "outputs": [],
      "source": [
        "!mkdir '/content/student_same_50/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKi3Se4kVoIT",
        "outputId": "ddf05099-6103-4014-80d3-8ccb94d31cd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 7ms/step\n",
            "Epoch 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5575: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 33s 29ms/step - categorical_crossentropy: 4.4059 - student_loss: 4.4059 - distillation_loss: 0.0030\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 4.4375 - accuracy: 0.0303\n",
            "Test Loss: 4.437527656555176, Test Accuracy: 0.030300000682473183\n",
            "Epoch 2:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 3.9705 - student_loss: 3.9702 - distillation_loss: 0.0029\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 3.8722 - accuracy: 0.1084\n",
            "Test Loss: 3.8722317218780518, Test Accuracy: 0.10840000212192535\n",
            "Epoch 3:\n",
            "782/782 [==============================] - 22s 29ms/step - categorical_crossentropy: 3.6765 - student_loss: 3.6759 - distillation_loss: 0.0028\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 3.7532 - accuracy: 0.1364\n",
            "Test Loss: 3.7531628608703613, Test Accuracy: 0.1363999992609024\n",
            "Epoch 4:\n",
            "782/782 [==============================] - 23s 29ms/step - categorical_crossentropy: 3.4491 - student_loss: 3.4480 - distillation_loss: 0.0027\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 3.5159 - accuracy: 0.1634\n",
            "Test Loss: 3.515850305557251, Test Accuracy: 0.16339999437332153\n",
            "Epoch 5:\n",
            "782/782 [==============================] - 22s 29ms/step - categorical_crossentropy: 3.2394 - student_loss: 3.2376 - distillation_loss: 0.0025\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 3.5161 - accuracy: 0.1773\n",
            "Test Loss: 3.516052722930908, Test Accuracy: 0.17730000615119934\n",
            "Epoch 6:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 3.0377 - student_loss: 3.0353 - distillation_loss: 0.0024\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 3.4647 - accuracy: 0.1923\n",
            "Test Loss: 3.4647152423858643, Test Accuracy: 0.1923000067472458\n",
            "Epoch 7:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 2.8420 - student_loss: 2.8395 - distillation_loss: 0.0024\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 3.5359 - accuracy: 0.1969\n",
            "Test Loss: 3.535907506942749, Test Accuracy: 0.19689999520778656\n",
            "Epoch 8:\n",
            "782/782 [==============================] - 22s 29ms/step - categorical_crossentropy: 2.6581 - student_loss: 2.6553 - distillation_loss: 0.0023\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 3.5229 - accuracy: 0.2017\n",
            "Test Loss: 3.522864818572998, Test Accuracy: 0.20170000195503235\n",
            "Epoch 9:\n",
            "782/782 [==============================] - 24s 30ms/step - categorical_crossentropy: 2.4817 - student_loss: 2.4786 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 3.5960 - accuracy: 0.2065\n",
            "Test Loss: 3.5959956645965576, Test Accuracy: 0.20649999380111694\n",
            "Epoch 10:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 2.3101 - student_loss: 2.3067 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 3.6011 - accuracy: 0.2149\n",
            "Test Loss: 3.60111403465271, Test Accuracy: 0.21490000188350677\n",
            "Epoch 11:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 2.1548 - student_loss: 2.1516 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 3.7190 - accuracy: 0.2118\n",
            "Test Loss: 3.718977689743042, Test Accuracy: 0.2117999941110611\n",
            "Epoch 12:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 2.0087 - student_loss: 2.0059 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 3.8204 - accuracy: 0.2085\n",
            "Test Loss: 3.820373773574829, Test Accuracy: 0.2084999978542328\n",
            "Epoch 13:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.8766 - student_loss: 1.8738 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 3.9323 - accuracy: 0.2174\n",
            "Test Loss: 3.9322774410247803, Test Accuracy: 0.21739999949932098\n",
            "Epoch 14:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.7515 - student_loss: 1.7487 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 4.0301 - accuracy: 0.2153\n",
            "Test Loss: 4.030148983001709, Test Accuracy: 0.21529999375343323\n",
            "Epoch 15:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.6296 - student_loss: 1.6265 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 4.2225 - accuracy: 0.2141\n",
            "Test Loss: 4.222482204437256, Test Accuracy: 0.21410000324249268\n",
            "Epoch 16:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.5217 - student_loss: 1.5195 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 4.3528 - accuracy: 0.2089\n",
            "Test Loss: 4.352842807769775, Test Accuracy: 0.20890000462532043\n",
            "Epoch 17:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.4166 - student_loss: 1.4138 - distillation_loss: 0.0023\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 4.4225 - accuracy: 0.2157\n",
            "Test Loss: 4.422545909881592, Test Accuracy: 0.21570000052452087\n",
            "Epoch 18:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.3306 - student_loss: 1.3282 - distillation_loss: 0.0023\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 4.6252 - accuracy: 0.2135\n",
            "Test Loss: 4.625211238861084, Test Accuracy: 0.2134999930858612\n",
            "Epoch 19:\n",
            "782/782 [==============================] - 24s 30ms/step - categorical_crossentropy: 1.2415 - student_loss: 1.2392 - distillation_loss: 0.0023\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 4.6989 - accuracy: 0.2110\n",
            "Test Loss: 4.6989240646362305, Test Accuracy: 0.210999995470047\n",
            "Epoch 20:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.1547 - student_loss: 1.1531 - distillation_loss: 0.0024\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 4.8062 - accuracy: 0.2124\n",
            "Test Loss: 4.806240558624268, Test Accuracy: 0.21240000426769257\n",
            "Epoch 21:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.0744 - student_loss: 1.0727 - distillation_loss: 0.0024\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 4.9430 - accuracy: 0.2072\n",
            "Test Loss: 4.943002223968506, Test Accuracy: 0.20720000565052032\n",
            "Epoch 22:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.0185 - student_loss: 1.0165 - distillation_loss: 0.0025\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 5.0255 - accuracy: 0.2140\n",
            "Test Loss: 5.025458335876465, Test Accuracy: 0.21400000154972076\n",
            "Epoch 23:\n",
            "782/782 [==============================] - 22s 29ms/step - categorical_crossentropy: 0.9464 - student_loss: 0.9446 - distillation_loss: 0.0025\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 5.1215 - accuracy: 0.2160\n",
            "Test Loss: 5.121548652648926, Test Accuracy: 0.2160000056028366\n",
            "Epoch 24:\n",
            "782/782 [==============================] - 23s 30ms/step - categorical_crossentropy: 0.8976 - student_loss: 0.8959 - distillation_loss: 0.0026\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 5.2623 - accuracy: 0.2175\n",
            "Test Loss: 5.262271881103516, Test Accuracy: 0.2175000011920929\n",
            "Epoch 25:\n",
            "782/782 [==============================] - 22s 29ms/step - categorical_crossentropy: 0.8392 - student_loss: 0.8380 - distillation_loss: 0.0026\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 5.2167 - accuracy: 0.2136\n",
            "Test Loss: 5.216651916503906, Test Accuracy: 0.21359999477863312\n"
          ]
        }
      ],
      "source": [
        "train_custom(distiller, x_train,y_train,x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFEgkn-4V38i"
      },
      "outputs": [],
      "source": [
        "del (student)\n",
        "gc.collect()\n",
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive(\"student_same_50\", 'zip', \"student_same_50\")\n",
        "colab_link = \"/content/student_same_50.zip\"\n",
        "gdrive_link = \"/content/drive/MyDrive/MobileNet_CIFAR100\"\n",
        "shutil.copy(colab_link, gdrive_link)"
      ],
      "metadata": {
        "id": "N1Tpio3AzHkb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5cea9eeb-f530-49fc-822d-c52e537758db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/MobileNet_CIFAR100/student_same_50.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMgWdqc_Vyr4"
      },
      "source": [
        "# Student same Alpha 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ispYXVKaV46U"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/base/mobilenetCIFAR100_init.tf'\n",
        "student = load_model(model_path)\n",
        "student_scratch = tf.keras.models.clone_model(student)\n",
        "\n",
        "distiller = Distiller(student=student, teacher=techer_model)\n",
        "distiller.compile(\n",
        "    optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001),\n",
        "    metrics=[tf.keras.metrics.CategoricalCrossentropy()],\n",
        "    student_loss_fn=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=tf.keras.losses.KLDivergence(),\n",
        "    alpha=0.5,\n",
        "    temperature=3,\n",
        ")\n",
        "\n",
        "filepath = '/content/student_same_90/'\n",
        "init_weights = filepath + model_name + dataset + '_init_weights.tf'\n",
        "init_model = filepath + model_name + dataset + '_init.tf'\n",
        "final_weights = filepath + model_name + dataset + '_final_weights.tf'\n",
        "final_model= filepath + model_name + dataset + 'final.tf'\n",
        "\n",
        "!mkdir '/content/student_same_90/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCOpusp6WA5k",
        "outputId": "359b0b9d-3c10-439f-ef9c-867273ed0376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 4ms/step\n",
            "Epoch 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5575: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 34s 28ms/step - categorical_crossentropy: 4.3861 - student_loss: 4.3861 - distillation_loss: 0.0030\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 4.3295 - accuracy: 0.0406\n",
            "Test Loss: 4.329462051391602, Test Accuracy: 0.0406000018119812\n",
            "Epoch 2:\n",
            "782/782 [==============================] - 21s 27ms/step - categorical_crossentropy: 3.9551 - student_loss: 3.9551 - distillation_loss: 0.0029\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 3.9086 - accuracy: 0.1125\n",
            "Test Loss: 3.9085676670074463, Test Accuracy: 0.11249999701976776\n",
            "Epoch 3:\n",
            "782/782 [==============================] - 21s 27ms/step - categorical_crossentropy: 3.6538 - student_loss: 3.6532 - distillation_loss: 0.0027\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 3.7741 - accuracy: 0.1296\n",
            "Test Loss: 3.7741281986236572, Test Accuracy: 0.12960000336170197\n",
            "Epoch 4:\n",
            "782/782 [==============================] - 21s 27ms/step - categorical_crossentropy: 3.4171 - student_loss: 3.4163 - distillation_loss: 0.0026\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 3.5202 - accuracy: 0.1719\n",
            "Test Loss: 3.5201938152313232, Test Accuracy: 0.17190000414848328\n",
            "Epoch 5:\n",
            "782/782 [==============================] - 21s 27ms/step - categorical_crossentropy: 3.2015 - student_loss: 3.1995 - distillation_loss: 0.0025\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 3.5131 - accuracy: 0.1789\n",
            "Test Loss: 3.5130515098571777, Test Accuracy: 0.17890000343322754\n",
            "Epoch 6:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 2.9949 - student_loss: 2.9925 - distillation_loss: 0.0024\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 3.4249 - accuracy: 0.2016\n",
            "Test Loss: 3.4249308109283447, Test Accuracy: 0.20160000026226044\n",
            "Epoch 7:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 2.7943 - student_loss: 2.7919 - distillation_loss: 0.0023\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 3.4369 - accuracy: 0.2084\n",
            "Test Loss: 3.4369261264801025, Test Accuracy: 0.20839999616146088\n",
            "Epoch 8:\n",
            "782/782 [==============================] - 24s 31ms/step - categorical_crossentropy: 2.5957 - student_loss: 2.5931 - distillation_loss: 0.0023\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 3.4858 - accuracy: 0.2060\n",
            "Test Loss: 3.485801935195923, Test Accuracy: 0.20600000023841858\n",
            "Epoch 9:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 2.4143 - student_loss: 2.4115 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 3.4923 - accuracy: 0.2176\n",
            "Test Loss: 3.4923458099365234, Test Accuracy: 0.2176000028848648\n",
            "Epoch 10:\n",
            "782/782 [==============================] - 21s 27ms/step - categorical_crossentropy: 2.2395 - student_loss: 2.2364 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 3.6221 - accuracy: 0.2215\n",
            "Test Loss: 3.6221001148223877, Test Accuracy: 0.2214999943971634\n",
            "Epoch 11:\n",
            "782/782 [==============================] - 22s 29ms/step - categorical_crossentropy: 2.0733 - student_loss: 2.0700 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 3.7925 - accuracy: 0.2119\n",
            "Test Loss: 3.792466402053833, Test Accuracy: 0.211899995803833\n",
            "Epoch 12:\n",
            "782/782 [==============================] - 21s 27ms/step - categorical_crossentropy: 1.9318 - student_loss: 1.9292 - distillation_loss: 0.0021\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 3.8885 - accuracy: 0.2214\n",
            "Test Loss: 3.888535499572754, Test Accuracy: 0.22139999270439148\n",
            "Epoch 13:\n",
            "782/782 [==============================] - 22s 29ms/step - categorical_crossentropy: 1.7914 - student_loss: 1.7890 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 4.1975 - accuracy: 0.2013\n",
            "Test Loss: 4.197455406188965, Test Accuracy: 0.2012999951839447\n",
            "Epoch 14:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.6708 - student_loss: 1.6677 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 4.1830 - accuracy: 0.1990\n",
            "Test Loss: 4.182967662811279, Test Accuracy: 0.19900000095367432\n",
            "Epoch 15:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.5618 - student_loss: 1.5590 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 4.4391 - accuracy: 0.2000\n",
            "Test Loss: 4.439136505126953, Test Accuracy: 0.20000000298023224\n",
            "Epoch 16:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.4373 - student_loss: 1.4345 - distillation_loss: 0.0022\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 4.3953 - accuracy: 0.2088\n",
            "Test Loss: 4.395330905914307, Test Accuracy: 0.20880000293254852\n",
            "Epoch 17:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.3500 - student_loss: 1.3473 - distillation_loss: 0.0023\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 4.4922 - accuracy: 0.2111\n",
            "Test Loss: 4.492221355438232, Test Accuracy: 0.2110999971628189\n",
            "Epoch 18:\n",
            "782/782 [==============================] - 23s 29ms/step - categorical_crossentropy: 1.2526 - student_loss: 1.2504 - distillation_loss: 0.0023\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 4.5652 - accuracy: 0.2138\n",
            "Test Loss: 4.565245628356934, Test Accuracy: 0.21379999816417694\n",
            "Epoch 19:\n",
            "782/782 [==============================] - 22s 29ms/step - categorical_crossentropy: 1.1718 - student_loss: 1.1698 - distillation_loss: 0.0024\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 4.6481 - accuracy: 0.2194\n",
            "Test Loss: 4.648134231567383, Test Accuracy: 0.21940000355243683\n",
            "Epoch 20:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.0937 - student_loss: 1.0918 - distillation_loss: 0.0024\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 4.8163 - accuracy: 0.2189\n",
            "Test Loss: 4.816291809082031, Test Accuracy: 0.21889999508857727\n",
            "Epoch 21:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 1.0187 - student_loss: 1.0168 - distillation_loss: 0.0025\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 4.9555 - accuracy: 0.2184\n",
            "Test Loss: 4.955511093139648, Test Accuracy: 0.2184000015258789\n",
            "Epoch 22:\n",
            "782/782 [==============================] - 23s 30ms/step - categorical_crossentropy: 0.9539 - student_loss: 0.9520 - distillation_loss: 0.0025\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 5.0904 - accuracy: 0.2128\n",
            "Test Loss: 5.0903778076171875, Test Accuracy: 0.21279999613761902\n",
            "Epoch 23:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 0.8734 - student_loss: 0.8717 - distillation_loss: 0.0026\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 5.4946 - accuracy: 0.2091\n",
            "Test Loss: 5.494610786437988, Test Accuracy: 0.20909999310970306\n",
            "Epoch 24:\n",
            "782/782 [==============================] - 22s 29ms/step - categorical_crossentropy: 0.8311 - student_loss: 0.8296 - distillation_loss: 0.0026\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 5.2526 - accuracy: 0.2140\n",
            "Test Loss: 5.252584934234619, Test Accuracy: 0.21400000154972076\n",
            "Epoch 25:\n",
            "782/782 [==============================] - 22s 28ms/step - categorical_crossentropy: 0.7727 - student_loss: 0.7716 - distillation_loss: 0.0027\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 5.2669 - accuracy: 0.2229\n",
            "Test Loss: 5.266885280609131, Test Accuracy: 0.22290000319480896\n"
          ]
        }
      ],
      "source": [
        "train_custom(distiller, x_train,y_train,x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYgkhmXlWC0H"
      },
      "outputs": [],
      "source": [
        "del (student)\n",
        "gc.collect()\n",
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive(\"student_same_90\", 'zip', \"student_same_90\")\n",
        "colab_link = \"/content/student_same_90.zip\"\n",
        "gdrive_link = \"/content/drive/MyDrive/MobileNet_CIFAR100\"\n",
        "shutil.copy(colab_link, gdrive_link)"
      ],
      "metadata": {
        "id": "YYcIh9efzLad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "edd5a534-74e1-4c72-be8e-06f54df9f902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/MobileNet_CIFAR100/student_same_90.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dvNBKhsWLqR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCQ1ucn3X8lA"
      },
      "source": [
        "---\n",
        "\n",
        "# Qunatisation\n",
        "\n",
        "https://github.com/sonalimedani/TF_Quantization/blob/master/quantization.ipynb\n",
        "\n",
        "https://medium.com/@sonalimedani/post-training-quantization-with-tensorflow-lite-on-a-keras-model-f373068966c4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X69D_tTXecfn"
      },
      "source": [
        "**Default**: 8 Bit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-3BCaalLyoM",
        "outputId": "a375cfa0-1d36-4fc7-eb07-cfce491e090b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 7ms/step - loss: 4.0083 - accuracy: 0.2912\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.008255481719971, 0.29120001196861267]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "path = '/content/base/mobilenetCIFAR100_final.tf'\n",
        "model = tf.keras.models.load_model(path)\n",
        "model.evaluate(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeW5pwbUZaPE"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/quantised_8_bit/'\n",
        "!mkdir '/content/quantised_8_bit/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAJQfzGfKjCT",
        "outputId": "a157442d-37cb-492c-c110-5451ad488552"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3963048"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()\n",
        "#saving converted model in \"converted_quant_model.tflite\" file\n",
        "open(filepath+\"8_bit.tflite\", \"wb\").write(tflite_quant_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Il7AvI1ZvPy",
        "outputId": "5743bb31-51be-496a-e472-b68514aaa1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Float model in Mb: 3.7794570922851562\n",
            "Quantized model in Mb: 3.7794570922851562\n",
            "Compression ratio: 967.541015625\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Float model in Mb:\", os.path.getsize(filepath+\"8_bit.tflite\") / float(2**20))\n",
        "print(\"Quantized model in Mb:\", os.path.getsize(filepath+\"8_bit.tflite\") / float(2**20))\n",
        "print(\"Compression ratio:\", os.path.getsize(filepath+\"8_bit.tflite\")/os.path.getsize(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4szzB8pWZ78D",
        "outputId": "53584612-02e1-4260-c376-3951400912a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29.110000000000003\n"
          ]
        }
      ],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=(filepath+\"8_bit.tflite\"))\n",
        "interpreter.allocate_tensors()\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "# Test model on some input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "acc=0\n",
        "results_default = pd.DataFrame()\n",
        "for i in range(len(x_test)):\n",
        "    input_data = x_test[i].reshape(input_shape)\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "    interpreter.invoke()\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    row = pd.DataFrame(output_data)\n",
        "    results_default = pd.concat([results_default, row], ignore_index=True)\n",
        "    if(np.argmax(output_data) == np.argmax(y_test[i])):\n",
        "        acc+=1\n",
        "acc = acc/len(x_test)\n",
        "print(acc*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "YpLAOjXtzwJd",
        "outputId": "8e7a06c6-37ac-493d-e649-007273aced00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                0             1             2             3             4   \\\n",
              "0     5.452338e-08  2.849827e-04  6.321326e-03  1.141326e-02  9.286149e-04   \n",
              "1     2.088002e-08  8.378078e-06  1.291897e-03  3.178457e-02  1.722837e-03   \n",
              "2     3.633799e-05  7.524704e-05  3.362759e-03  5.714813e-02  2.238977e-02   \n",
              "3     1.320306e-05  1.132022e-02  2.261114e-02  6.120601e-04  2.965458e-03   \n",
              "4     2.020323e-07  6.495440e-07  3.098056e-08  5.588389e-08  4.793246e-06   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995  2.901501e-02  1.307471e-06  3.338182e-07  1.324926e-10  5.571842e-13   \n",
              "9996  1.063819e-05  4.182215e-04  3.892347e-06  2.640784e-04  1.121478e-03   \n",
              "9997  1.214744e-07  1.448190e-04  5.050247e-07  2.085097e-03  9.864735e-03   \n",
              "9998  8.087349e-08  4.844283e-06  1.110292e-05  7.558180e-04  8.474008e-03   \n",
              "9999  1.190404e-02  5.076510e-04  4.429730e-05  8.883022e-06  7.028285e-07   \n",
              "\n",
              "                5             6             7             8             9   \\\n",
              "0     3.105085e-03  7.433397e-08  1.550702e-07  2.123508e-06  6.284380e-04   \n",
              "1     4.940326e-07  2.526877e-05  5.851495e-07  3.774145e-05  1.846994e-03   \n",
              "2     6.676562e-06  1.954322e-03  7.788763e-05  5.603276e-04  2.301750e-02   \n",
              "3     1.676298e-03  1.886240e-04  1.368031e-03  2.363846e-03  2.495940e-03   \n",
              "4     2.821875e-06  2.187248e-11  3.545757e-07  6.991724e-10  1.930519e-06   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995  3.894269e-14  3.393763e-04  6.855845e-05  4.212565e-10  9.541813e-10   \n",
              "9996  1.590311e-10  2.294818e-05  6.623085e-04  2.325276e-07  3.674884e-05   \n",
              "9997  1.460686e-09  2.237987e-04  5.424401e-05  2.783195e-05  1.201779e-07   \n",
              "9998  7.583412e-10  7.085132e-05  4.455133e-05  7.365041e-06  1.658380e-06   \n",
              "9999  5.005170e-12  4.168592e-04  1.942184e-04  1.797759e-03  3.840927e-07   \n",
              "\n",
              "      ...            90            91            92            93  \\\n",
              "0     ...  4.622587e-03  1.714653e-03  1.912657e-06  5.635980e-05   \n",
              "1     ...  2.319049e-05  1.871396e-05  3.047042e-05  2.087224e-04   \n",
              "2     ...  9.433895e-03  1.865405e-03  1.790594e-04  1.546065e-03   \n",
              "3     ...  9.644844e-03  1.921365e-02  2.068224e-04  2.884190e-02   \n",
              "4     ...  1.335863e-07  4.245918e-07  4.104295e-09  2.185045e-09   \n",
              "...   ...           ...           ...           ...           ...   \n",
              "9995  ...  1.543272e-12  8.821090e-12  1.395297e-01  4.163681e-09   \n",
              "9996  ...  1.873763e-09  5.381599e-05  7.858488e-05  3.926896e-03   \n",
              "9997  ...  7.210631e-05  3.828305e-04  1.097433e-05  1.113080e-03   \n",
              "9998  ...  1.088419e-07  1.169956e-04  5.785576e-06  5.110787e-04   \n",
              "9999  ...  1.113382e-04  1.319585e-05  4.631745e-01  1.559763e-08   \n",
              "\n",
              "                94            95            96            97            98  \\\n",
              "0     1.124146e-07  5.926884e-04  5.636826e-06  5.090290e-07  1.983243e-05   \n",
              "1     3.175396e-06  6.241978e-07  4.633480e-07  1.442286e-01  5.997722e-03   \n",
              "2     2.231831e-09  7.148984e-06  1.024043e-05  1.155120e-06  1.586085e-05   \n",
              "3     6.860828e-05  8.076882e-06  1.280066e-04  4.069741e-04  2.329636e-04   \n",
              "4     2.996216e-05  4.556009e-07  1.036504e-08  5.036754e-19  5.915668e-12   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995  4.290337e-21  2.777431e-13  3.271207e-11  1.231069e-14  3.509395e-09   \n",
              "9996  6.596240e-16  3.228826e-10  6.360306e-06  5.104100e-07  1.136990e-06   \n",
              "9997  8.333471e-15  2.741219e-11  2.670020e-03  9.163329e-06  6.389812e-07   \n",
              "9998  2.044472e-14  2.609933e-10  7.508082e-04  1.437614e-03  1.377420e-05   \n",
              "9999  1.284039e-13  2.464857e-11  2.183463e-12  7.523254e-09  1.580878e-05   \n",
              "\n",
              "            99  \n",
              "0     0.000058  \n",
              "1     0.000047  \n",
              "2     0.000012  \n",
              "3     0.001960  \n",
              "4     0.000355  \n",
              "...        ...  \n",
              "9995  0.000008  \n",
              "9996  0.000197  \n",
              "9997  0.000617  \n",
              "9998  0.004005  \n",
              "9999  0.023723  \n",
              "\n",
              "[10000 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-653b7a21-dad0-4273-8e02-d9e882496b4d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.452338e-08</td>\n",
              "      <td>2.849827e-04</td>\n",
              "      <td>6.321326e-03</td>\n",
              "      <td>1.141326e-02</td>\n",
              "      <td>9.286149e-04</td>\n",
              "      <td>3.105085e-03</td>\n",
              "      <td>7.433397e-08</td>\n",
              "      <td>1.550702e-07</td>\n",
              "      <td>2.123508e-06</td>\n",
              "      <td>6.284380e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>4.622587e-03</td>\n",
              "      <td>1.714653e-03</td>\n",
              "      <td>1.912657e-06</td>\n",
              "      <td>5.635980e-05</td>\n",
              "      <td>1.124146e-07</td>\n",
              "      <td>5.926884e-04</td>\n",
              "      <td>5.636826e-06</td>\n",
              "      <td>5.090290e-07</td>\n",
              "      <td>1.983243e-05</td>\n",
              "      <td>0.000058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.088002e-08</td>\n",
              "      <td>8.378078e-06</td>\n",
              "      <td>1.291897e-03</td>\n",
              "      <td>3.178457e-02</td>\n",
              "      <td>1.722837e-03</td>\n",
              "      <td>4.940326e-07</td>\n",
              "      <td>2.526877e-05</td>\n",
              "      <td>5.851495e-07</td>\n",
              "      <td>3.774145e-05</td>\n",
              "      <td>1.846994e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>2.319049e-05</td>\n",
              "      <td>1.871396e-05</td>\n",
              "      <td>3.047042e-05</td>\n",
              "      <td>2.087224e-04</td>\n",
              "      <td>3.175396e-06</td>\n",
              "      <td>6.241978e-07</td>\n",
              "      <td>4.633480e-07</td>\n",
              "      <td>1.442286e-01</td>\n",
              "      <td>5.997722e-03</td>\n",
              "      <td>0.000047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.633799e-05</td>\n",
              "      <td>7.524704e-05</td>\n",
              "      <td>3.362759e-03</td>\n",
              "      <td>5.714813e-02</td>\n",
              "      <td>2.238977e-02</td>\n",
              "      <td>6.676562e-06</td>\n",
              "      <td>1.954322e-03</td>\n",
              "      <td>7.788763e-05</td>\n",
              "      <td>5.603276e-04</td>\n",
              "      <td>2.301750e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>9.433895e-03</td>\n",
              "      <td>1.865405e-03</td>\n",
              "      <td>1.790594e-04</td>\n",
              "      <td>1.546065e-03</td>\n",
              "      <td>2.231831e-09</td>\n",
              "      <td>7.148984e-06</td>\n",
              "      <td>1.024043e-05</td>\n",
              "      <td>1.155120e-06</td>\n",
              "      <td>1.586085e-05</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.320306e-05</td>\n",
              "      <td>1.132022e-02</td>\n",
              "      <td>2.261114e-02</td>\n",
              "      <td>6.120601e-04</td>\n",
              "      <td>2.965458e-03</td>\n",
              "      <td>1.676298e-03</td>\n",
              "      <td>1.886240e-04</td>\n",
              "      <td>1.368031e-03</td>\n",
              "      <td>2.363846e-03</td>\n",
              "      <td>2.495940e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>9.644844e-03</td>\n",
              "      <td>1.921365e-02</td>\n",
              "      <td>2.068224e-04</td>\n",
              "      <td>2.884190e-02</td>\n",
              "      <td>6.860828e-05</td>\n",
              "      <td>8.076882e-06</td>\n",
              "      <td>1.280066e-04</td>\n",
              "      <td>4.069741e-04</td>\n",
              "      <td>2.329636e-04</td>\n",
              "      <td>0.001960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.020323e-07</td>\n",
              "      <td>6.495440e-07</td>\n",
              "      <td>3.098056e-08</td>\n",
              "      <td>5.588389e-08</td>\n",
              "      <td>4.793246e-06</td>\n",
              "      <td>2.821875e-06</td>\n",
              "      <td>2.187248e-11</td>\n",
              "      <td>3.545757e-07</td>\n",
              "      <td>6.991724e-10</td>\n",
              "      <td>1.930519e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>1.335863e-07</td>\n",
              "      <td>4.245918e-07</td>\n",
              "      <td>4.104295e-09</td>\n",
              "      <td>2.185045e-09</td>\n",
              "      <td>2.996216e-05</td>\n",
              "      <td>4.556009e-07</td>\n",
              "      <td>1.036504e-08</td>\n",
              "      <td>5.036754e-19</td>\n",
              "      <td>5.915668e-12</td>\n",
              "      <td>0.000355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>2.901501e-02</td>\n",
              "      <td>1.307471e-06</td>\n",
              "      <td>3.338182e-07</td>\n",
              "      <td>1.324926e-10</td>\n",
              "      <td>5.571842e-13</td>\n",
              "      <td>3.894269e-14</td>\n",
              "      <td>3.393763e-04</td>\n",
              "      <td>6.855845e-05</td>\n",
              "      <td>4.212565e-10</td>\n",
              "      <td>9.541813e-10</td>\n",
              "      <td>...</td>\n",
              "      <td>1.543272e-12</td>\n",
              "      <td>8.821090e-12</td>\n",
              "      <td>1.395297e-01</td>\n",
              "      <td>4.163681e-09</td>\n",
              "      <td>4.290337e-21</td>\n",
              "      <td>2.777431e-13</td>\n",
              "      <td>3.271207e-11</td>\n",
              "      <td>1.231069e-14</td>\n",
              "      <td>3.509395e-09</td>\n",
              "      <td>0.000008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>1.063819e-05</td>\n",
              "      <td>4.182215e-04</td>\n",
              "      <td>3.892347e-06</td>\n",
              "      <td>2.640784e-04</td>\n",
              "      <td>1.121478e-03</td>\n",
              "      <td>1.590311e-10</td>\n",
              "      <td>2.294818e-05</td>\n",
              "      <td>6.623085e-04</td>\n",
              "      <td>2.325276e-07</td>\n",
              "      <td>3.674884e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>1.873763e-09</td>\n",
              "      <td>5.381599e-05</td>\n",
              "      <td>7.858488e-05</td>\n",
              "      <td>3.926896e-03</td>\n",
              "      <td>6.596240e-16</td>\n",
              "      <td>3.228826e-10</td>\n",
              "      <td>6.360306e-06</td>\n",
              "      <td>5.104100e-07</td>\n",
              "      <td>1.136990e-06</td>\n",
              "      <td>0.000197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>1.214744e-07</td>\n",
              "      <td>1.448190e-04</td>\n",
              "      <td>5.050247e-07</td>\n",
              "      <td>2.085097e-03</td>\n",
              "      <td>9.864735e-03</td>\n",
              "      <td>1.460686e-09</td>\n",
              "      <td>2.237987e-04</td>\n",
              "      <td>5.424401e-05</td>\n",
              "      <td>2.783195e-05</td>\n",
              "      <td>1.201779e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>7.210631e-05</td>\n",
              "      <td>3.828305e-04</td>\n",
              "      <td>1.097433e-05</td>\n",
              "      <td>1.113080e-03</td>\n",
              "      <td>8.333471e-15</td>\n",
              "      <td>2.741219e-11</td>\n",
              "      <td>2.670020e-03</td>\n",
              "      <td>9.163329e-06</td>\n",
              "      <td>6.389812e-07</td>\n",
              "      <td>0.000617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>8.087349e-08</td>\n",
              "      <td>4.844283e-06</td>\n",
              "      <td>1.110292e-05</td>\n",
              "      <td>7.558180e-04</td>\n",
              "      <td>8.474008e-03</td>\n",
              "      <td>7.583412e-10</td>\n",
              "      <td>7.085132e-05</td>\n",
              "      <td>4.455133e-05</td>\n",
              "      <td>7.365041e-06</td>\n",
              "      <td>1.658380e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>1.088419e-07</td>\n",
              "      <td>1.169956e-04</td>\n",
              "      <td>5.785576e-06</td>\n",
              "      <td>5.110787e-04</td>\n",
              "      <td>2.044472e-14</td>\n",
              "      <td>2.609933e-10</td>\n",
              "      <td>7.508082e-04</td>\n",
              "      <td>1.437614e-03</td>\n",
              "      <td>1.377420e-05</td>\n",
              "      <td>0.004005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>1.190404e-02</td>\n",
              "      <td>5.076510e-04</td>\n",
              "      <td>4.429730e-05</td>\n",
              "      <td>8.883022e-06</td>\n",
              "      <td>7.028285e-07</td>\n",
              "      <td>5.005170e-12</td>\n",
              "      <td>4.168592e-04</td>\n",
              "      <td>1.942184e-04</td>\n",
              "      <td>1.797759e-03</td>\n",
              "      <td>3.840927e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>1.113382e-04</td>\n",
              "      <td>1.319585e-05</td>\n",
              "      <td>4.631745e-01</td>\n",
              "      <td>1.559763e-08</td>\n",
              "      <td>1.284039e-13</td>\n",
              "      <td>2.464857e-11</td>\n",
              "      <td>2.183463e-12</td>\n",
              "      <td>7.523254e-09</td>\n",
              "      <td>1.580878e-05</td>\n",
              "      <td>0.023723</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 100 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-653b7a21-dad0-4273-8e02-d9e882496b4d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-653b7a21-dad0-4273-8e02-d9e882496b4d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-653b7a21-dad0-4273-8e02-d9e882496b4d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e2d38c45-ff97-44cd-a847-d2e3f3f62257\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e2d38c45-ff97-44cd-a847-d2e3f3f62257')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e2d38c45-ff97-44cd-a847-d2e3f3f62257 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "results_default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6h3FAVP8c0A3"
      },
      "outputs": [],
      "source": [
        "results_default.to_csv((filepath+\"25_softmax.csv\"),index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpxVyxMGefBb"
      },
      "source": [
        "**16 bit**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlVMMwy1O-E4"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIrx8SJkaK2g"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/quantised_16_bit/'\n",
        "!mkdir '/content/quantised_16_bit/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVkn8lg5cWIa",
        "outputId": "956733f3-1696-4020-ab2e-945a110583a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7574728"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_quant_model = converter.convert()\n",
        "#saving converted model in \"converted_quant_model.tflite\" file\n",
        "open((filepath +\"16_bit.tflite\"), \"wb\").write(tflite_quant_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S89XWCTbGHF",
        "outputId": "2a6147ec-b420-4163-aa99-0d66ecc3c793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Float model in Mb: 7.223823547363281\n",
            "Quantized model in Mb: 7.223823547363281\n",
            "Compression ratio: 1849.298828125\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Float model in Mb:\", os.path.getsize(filepath +\"16_bit.tflite\") / float(2**20))\n",
        "print(\"Quantized model in Mb:\", os.path.getsize(filepath +\"16_bit.tflite\") / float(2**20))\n",
        "print(\"Compression ratio:\", os.path.getsize(filepath +\"16_bit.tflite\")/os.path.getsize(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dGGvQ6SZlyV",
        "outputId": "456d3a11-e6c3-4289-b2ad-3977a2f0caf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29.17\n"
          ]
        }
      ],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=filepath +\"16_bit.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "# Test model on some input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "acc=0\n",
        "results_16_b = pd.DataFrame()\n",
        "for i in range(len(x_test)):\n",
        "    input_data = x_test[i].reshape(input_shape)\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "    interpreter.invoke()\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    row = pd.DataFrame(output_data)\n",
        "    results_16_b = pd.concat([results_16_b, row], ignore_index=True)\n",
        "    if(np.argmax(output_data) == np.argmax(y_test[i])):\n",
        "        acc+=1\n",
        "acc = acc/len(x_test)\n",
        "print(acc*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "fm8vJ_qrfyYt",
        "outputId": "8d2ef8ef-6c0f-481a-a28c-da44d284d8ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                0             1             2             3             4   \\\n",
              "0     9.989285e-08  3.464906e-04  7.190186e-03  1.153481e-02  8.252924e-04   \n",
              "1     2.885227e-08  7.584696e-06  1.495656e-03  2.860395e-02  1.371991e-03   \n",
              "2     5.104087e-05  7.815671e-05  3.846474e-03  4.027948e-02  1.462926e-02   \n",
              "3     1.195435e-05  1.114304e-02  2.161769e-02  5.088960e-04  2.875378e-03   \n",
              "4     2.191451e-07  6.397751e-07  2.852803e-08  4.717817e-08  4.933849e-06   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995  3.326394e-02  1.533877e-06  4.577280e-07  1.643656e-10  8.546477e-13   \n",
              "9996  9.544151e-06  3.815806e-04  3.110191e-06  2.236211e-04  1.345005e-03   \n",
              "9997  1.622193e-07  2.012198e-04  5.171330e-07  1.957895e-03  1.122039e-02   \n",
              "9998  8.825335e-08  5.588958e-06  1.364169e-05  7.055389e-04  9.971334e-03   \n",
              "9999  1.311024e-02  4.470018e-04  3.822795e-05  8.464888e-06  6.376882e-07   \n",
              "\n",
              "                5             6             7             8             9   \\\n",
              "0     4.016354e-03  1.005441e-07  1.268306e-07  1.870124e-06  7.433856e-04   \n",
              "1     5.713520e-07  2.314486e-05  4.363962e-07  3.909201e-05  1.852558e-03   \n",
              "2     8.516764e-06  2.386707e-03  6.125534e-05  6.039416e-04  2.883859e-02   \n",
              "3     1.727467e-03  1.899011e-04  1.189478e-03  2.467590e-03  2.283339e-03   \n",
              "4     2.634130e-06  1.884995e-11  2.747632e-07  5.535369e-10  2.070638e-06   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995  6.725190e-14  4.331448e-04  7.936892e-05  6.461967e-10  1.429200e-09   \n",
              "9996  1.325867e-10  1.869916e-05  4.747607e-04  1.862704e-07  3.066526e-05   \n",
              "9997  2.350848e-09  2.930266e-04  7.300150e-05  3.660507e-05  1.746467e-07   \n",
              "9998  9.126355e-10  7.697695e-05  4.669961e-05  9.630312e-06  1.800874e-06   \n",
              "9999  4.762870e-12  4.219195e-04  2.109617e-04  1.607138e-03  3.492771e-07   \n",
              "\n",
              "      ...            90            91            92            93  \\\n",
              "0     ...  4.856254e-03  2.109881e-03  2.593811e-06  5.297093e-05   \n",
              "1     ...  2.497278e-05  1.649264e-05  3.003246e-05  1.653987e-04   \n",
              "2     ...  8.530158e-03  2.009114e-03  1.897010e-04  1.396264e-03   \n",
              "3     ...  9.749992e-03  2.178408e-02  1.866283e-04  2.821786e-02   \n",
              "4     ...  1.133880e-07  4.104600e-07  4.832957e-09  2.165897e-09   \n",
              "...   ...           ...           ...           ...           ...   \n",
              "9995  ...  2.409386e-12  1.434053e-11  1.448480e-01  5.781423e-09   \n",
              "9996  ...  1.505716e-09  4.465251e-05  7.083185e-05  3.562691e-03   \n",
              "9997  ...  8.442358e-05  4.960940e-04  1.558068e-05  1.557577e-03   \n",
              "9998  ...  1.807370e-07  1.730063e-04  6.509201e-06  4.681767e-04   \n",
              "9999  ...  1.068312e-04  1.340064e-05  4.701611e-01  1.458424e-08   \n",
              "\n",
              "                94            95            96            97            98  \\\n",
              "0     1.668334e-07  4.977926e-04  6.061704e-06  8.278136e-07  2.706404e-05   \n",
              "1     3.665153e-06  5.067588e-07  3.961121e-07  1.480325e-01  7.262730e-03   \n",
              "2     2.584470e-09  7.359728e-06  9.315252e-06  1.582255e-06  2.248465e-05   \n",
              "3     6.159856e-05  7.447696e-06  1.340986e-04  4.054749e-04  1.998353e-04   \n",
              "4     3.483851e-05  3.872376e-07  7.000555e-09  3.379301e-19  5.315270e-12   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995  1.362054e-20  4.230458e-13  4.711811e-11  1.782263e-14  5.390298e-09   \n",
              "9996  5.365574e-16  1.938091e-10  7.543567e-06  3.938268e-07  1.033017e-06   \n",
              "9997  1.445097e-14  2.818455e-11  4.852056e-03  6.479925e-06  5.810603e-07   \n",
              "9998  2.009575e-14  2.074569e-10  7.487652e-04  1.332764e-03  1.621830e-05   \n",
              "9999  1.522931e-13  2.077236e-11  2.449266e-12  6.393183e-09  1.296776e-05   \n",
              "\n",
              "            99  \n",
              "0     0.000063  \n",
              "1     0.000039  \n",
              "2     0.000011  \n",
              "3     0.002027  \n",
              "4     0.000357  \n",
              "...        ...  \n",
              "9995  0.000011  \n",
              "9996  0.000183  \n",
              "9997  0.001003  \n",
              "9998  0.006272  \n",
              "9999  0.024146  \n",
              "\n",
              "[10000 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ada60056-7648-4304-982e-b93e050a5390\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.989285e-08</td>\n",
              "      <td>3.464906e-04</td>\n",
              "      <td>7.190186e-03</td>\n",
              "      <td>1.153481e-02</td>\n",
              "      <td>8.252924e-04</td>\n",
              "      <td>4.016354e-03</td>\n",
              "      <td>1.005441e-07</td>\n",
              "      <td>1.268306e-07</td>\n",
              "      <td>1.870124e-06</td>\n",
              "      <td>7.433856e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>4.856254e-03</td>\n",
              "      <td>2.109881e-03</td>\n",
              "      <td>2.593811e-06</td>\n",
              "      <td>5.297093e-05</td>\n",
              "      <td>1.668334e-07</td>\n",
              "      <td>4.977926e-04</td>\n",
              "      <td>6.061704e-06</td>\n",
              "      <td>8.278136e-07</td>\n",
              "      <td>2.706404e-05</td>\n",
              "      <td>0.000063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.885227e-08</td>\n",
              "      <td>7.584696e-06</td>\n",
              "      <td>1.495656e-03</td>\n",
              "      <td>2.860395e-02</td>\n",
              "      <td>1.371991e-03</td>\n",
              "      <td>5.713520e-07</td>\n",
              "      <td>2.314486e-05</td>\n",
              "      <td>4.363962e-07</td>\n",
              "      <td>3.909201e-05</td>\n",
              "      <td>1.852558e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>2.497278e-05</td>\n",
              "      <td>1.649264e-05</td>\n",
              "      <td>3.003246e-05</td>\n",
              "      <td>1.653987e-04</td>\n",
              "      <td>3.665153e-06</td>\n",
              "      <td>5.067588e-07</td>\n",
              "      <td>3.961121e-07</td>\n",
              "      <td>1.480325e-01</td>\n",
              "      <td>7.262730e-03</td>\n",
              "      <td>0.000039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.104087e-05</td>\n",
              "      <td>7.815671e-05</td>\n",
              "      <td>3.846474e-03</td>\n",
              "      <td>4.027948e-02</td>\n",
              "      <td>1.462926e-02</td>\n",
              "      <td>8.516764e-06</td>\n",
              "      <td>2.386707e-03</td>\n",
              "      <td>6.125534e-05</td>\n",
              "      <td>6.039416e-04</td>\n",
              "      <td>2.883859e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>8.530158e-03</td>\n",
              "      <td>2.009114e-03</td>\n",
              "      <td>1.897010e-04</td>\n",
              "      <td>1.396264e-03</td>\n",
              "      <td>2.584470e-09</td>\n",
              "      <td>7.359728e-06</td>\n",
              "      <td>9.315252e-06</td>\n",
              "      <td>1.582255e-06</td>\n",
              "      <td>2.248465e-05</td>\n",
              "      <td>0.000011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.195435e-05</td>\n",
              "      <td>1.114304e-02</td>\n",
              "      <td>2.161769e-02</td>\n",
              "      <td>5.088960e-04</td>\n",
              "      <td>2.875378e-03</td>\n",
              "      <td>1.727467e-03</td>\n",
              "      <td>1.899011e-04</td>\n",
              "      <td>1.189478e-03</td>\n",
              "      <td>2.467590e-03</td>\n",
              "      <td>2.283339e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>9.749992e-03</td>\n",
              "      <td>2.178408e-02</td>\n",
              "      <td>1.866283e-04</td>\n",
              "      <td>2.821786e-02</td>\n",
              "      <td>6.159856e-05</td>\n",
              "      <td>7.447696e-06</td>\n",
              "      <td>1.340986e-04</td>\n",
              "      <td>4.054749e-04</td>\n",
              "      <td>1.998353e-04</td>\n",
              "      <td>0.002027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.191451e-07</td>\n",
              "      <td>6.397751e-07</td>\n",
              "      <td>2.852803e-08</td>\n",
              "      <td>4.717817e-08</td>\n",
              "      <td>4.933849e-06</td>\n",
              "      <td>2.634130e-06</td>\n",
              "      <td>1.884995e-11</td>\n",
              "      <td>2.747632e-07</td>\n",
              "      <td>5.535369e-10</td>\n",
              "      <td>2.070638e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>1.133880e-07</td>\n",
              "      <td>4.104600e-07</td>\n",
              "      <td>4.832957e-09</td>\n",
              "      <td>2.165897e-09</td>\n",
              "      <td>3.483851e-05</td>\n",
              "      <td>3.872376e-07</td>\n",
              "      <td>7.000555e-09</td>\n",
              "      <td>3.379301e-19</td>\n",
              "      <td>5.315270e-12</td>\n",
              "      <td>0.000357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>3.326394e-02</td>\n",
              "      <td>1.533877e-06</td>\n",
              "      <td>4.577280e-07</td>\n",
              "      <td>1.643656e-10</td>\n",
              "      <td>8.546477e-13</td>\n",
              "      <td>6.725190e-14</td>\n",
              "      <td>4.331448e-04</td>\n",
              "      <td>7.936892e-05</td>\n",
              "      <td>6.461967e-10</td>\n",
              "      <td>1.429200e-09</td>\n",
              "      <td>...</td>\n",
              "      <td>2.409386e-12</td>\n",
              "      <td>1.434053e-11</td>\n",
              "      <td>1.448480e-01</td>\n",
              "      <td>5.781423e-09</td>\n",
              "      <td>1.362054e-20</td>\n",
              "      <td>4.230458e-13</td>\n",
              "      <td>4.711811e-11</td>\n",
              "      <td>1.782263e-14</td>\n",
              "      <td>5.390298e-09</td>\n",
              "      <td>0.000011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9.544151e-06</td>\n",
              "      <td>3.815806e-04</td>\n",
              "      <td>3.110191e-06</td>\n",
              "      <td>2.236211e-04</td>\n",
              "      <td>1.345005e-03</td>\n",
              "      <td>1.325867e-10</td>\n",
              "      <td>1.869916e-05</td>\n",
              "      <td>4.747607e-04</td>\n",
              "      <td>1.862704e-07</td>\n",
              "      <td>3.066526e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>1.505716e-09</td>\n",
              "      <td>4.465251e-05</td>\n",
              "      <td>7.083185e-05</td>\n",
              "      <td>3.562691e-03</td>\n",
              "      <td>5.365574e-16</td>\n",
              "      <td>1.938091e-10</td>\n",
              "      <td>7.543567e-06</td>\n",
              "      <td>3.938268e-07</td>\n",
              "      <td>1.033017e-06</td>\n",
              "      <td>0.000183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>1.622193e-07</td>\n",
              "      <td>2.012198e-04</td>\n",
              "      <td>5.171330e-07</td>\n",
              "      <td>1.957895e-03</td>\n",
              "      <td>1.122039e-02</td>\n",
              "      <td>2.350848e-09</td>\n",
              "      <td>2.930266e-04</td>\n",
              "      <td>7.300150e-05</td>\n",
              "      <td>3.660507e-05</td>\n",
              "      <td>1.746467e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>8.442358e-05</td>\n",
              "      <td>4.960940e-04</td>\n",
              "      <td>1.558068e-05</td>\n",
              "      <td>1.557577e-03</td>\n",
              "      <td>1.445097e-14</td>\n",
              "      <td>2.818455e-11</td>\n",
              "      <td>4.852056e-03</td>\n",
              "      <td>6.479925e-06</td>\n",
              "      <td>5.810603e-07</td>\n",
              "      <td>0.001003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>8.825335e-08</td>\n",
              "      <td>5.588958e-06</td>\n",
              "      <td>1.364169e-05</td>\n",
              "      <td>7.055389e-04</td>\n",
              "      <td>9.971334e-03</td>\n",
              "      <td>9.126355e-10</td>\n",
              "      <td>7.697695e-05</td>\n",
              "      <td>4.669961e-05</td>\n",
              "      <td>9.630312e-06</td>\n",
              "      <td>1.800874e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>1.807370e-07</td>\n",
              "      <td>1.730063e-04</td>\n",
              "      <td>6.509201e-06</td>\n",
              "      <td>4.681767e-04</td>\n",
              "      <td>2.009575e-14</td>\n",
              "      <td>2.074569e-10</td>\n",
              "      <td>7.487652e-04</td>\n",
              "      <td>1.332764e-03</td>\n",
              "      <td>1.621830e-05</td>\n",
              "      <td>0.006272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>1.311024e-02</td>\n",
              "      <td>4.470018e-04</td>\n",
              "      <td>3.822795e-05</td>\n",
              "      <td>8.464888e-06</td>\n",
              "      <td>6.376882e-07</td>\n",
              "      <td>4.762870e-12</td>\n",
              "      <td>4.219195e-04</td>\n",
              "      <td>2.109617e-04</td>\n",
              "      <td>1.607138e-03</td>\n",
              "      <td>3.492771e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>1.068312e-04</td>\n",
              "      <td>1.340064e-05</td>\n",
              "      <td>4.701611e-01</td>\n",
              "      <td>1.458424e-08</td>\n",
              "      <td>1.522931e-13</td>\n",
              "      <td>2.077236e-11</td>\n",
              "      <td>2.449266e-12</td>\n",
              "      <td>6.393183e-09</td>\n",
              "      <td>1.296776e-05</td>\n",
              "      <td>0.024146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 100 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ada60056-7648-4304-982e-b93e050a5390')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ada60056-7648-4304-982e-b93e050a5390 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ada60056-7648-4304-982e-b93e050a5390');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ddc6f540-e117-47f9-9f91-7f9e75650804\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ddc6f540-e117-47f9-9f91-7f9e75650804')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ddc6f540-e117-47f9-9f91-7f9e75650804 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "results_16_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sYfcMpA0Ciz"
      },
      "outputs": [],
      "source": [
        "results_16_b.to_csv(filepath +'25_softmax.csv',index =False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sIXOiBbSgxM"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "duQtnTAHSp03",
        "outputId": "2e004f4b-c77c-4898-bd4c-2e81559bd170"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2dc3f91d-5ce1-436c-a8b0-1ac9db9f6545\", \"quantised_16_bit.zip\", 12472960)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "shutil.make_archive(\"quantised_16_bit\", 'zip', \"quantised_16_bit\")\n",
        "files.download(\"quantised_16_bit.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "eWkTJRnsS6I1",
        "outputId": "ed233929-097a-4424-e6f1-2d4ead30d5d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ab087461-ffcf-4302-997c-52b8df54f9bf\", \"quantised_8_bit.zip\", 8824621)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "shutil.make_archive(\"quantised_8_bit\", 'zip', \"quantised_8_bit\")\n",
        "files.download(\"quantised_8_bit.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}